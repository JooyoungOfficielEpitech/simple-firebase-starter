/**
 * ìŒì • ë¶„ì„ ì„œë¹„ìŠ¤
 * ì‹¤ì‹œê°„ í”¼ì¹˜ ê²€ì¶œê³¼ MusicXML ìŒì • ë°ì´í„° ë¹„êµ ë¶„ì„
 */

import { Audio } from "expo-av"
import { PitchDetector, PitchDetectionResult, PitchUtils } from "./pitchDetection"
import type { LyricItem } from "@/services/musicxml/musicXMLParser"

export interface PitchAnalysisResult {
  currentPitch: PitchDetectionResult
  targetPitch: {
    frequency: number
    note: string
    octave: number
  } | null
  accuracy: number           // 0-1 ì •í™•ë„ ì ìˆ˜
  centsDifference: number    // ì„¼íŠ¸ ë‹¨ìœ„ ì°¨ì´ (-100 ~ +100)
  isOnPitch: boolean         // ì •í™•í•œ ìŒì •ì¸ì§€
  lyricText: string         // í˜„ì¬ ê°€ì‚¬
  timestamp: number         // ë¶„ì„ ì‹œì 
}

export interface PitchAnalysisConfig {
  recordingOptions: {
    android: {
      extension: ".wav"
      outputFormat: number
      audioEncoder: number
      sampleRate: number
      numberOfChannels: number
      bitRate: number
    }
    ios: {
      extension: ".wav"
      audioQuality: number
      sampleRate: number
      numberOfChannels: number
      bitRate: number
      linearPCMBitDepth: number
      linearPCMIsBigEndian: boolean
      linearPCMIsFloat: boolean
    }
  }
  analysisInterval: number    // ë¶„ì„ ê°„ê²© (ms)
  bufferSize: number         // ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸°
  pitchTolerance: number     // ìŒì • í—ˆìš© ì˜¤ì°¨ (cents)
  minConfidence: number      // ìµœì†Œ ì‹ ë¢°ë„
}

export class PitchAnalysisService {
  private pitchDetector: PitchDetector
  private recording: Audio.Recording | null = null
  private analysisTimer: NodeJS.Timeout | null = null
  private config: PitchAnalysisConfig
  private isAnalyzing = false
  private currentLyrics: LyricItem[] = []
  private analysisCallback: ((result: PitchAnalysisResult) => void) | null = null
  private analysisStartTime: number = 0

  constructor(config: Partial<PitchAnalysisConfig> = {}) {
    this.config = {
      recordingOptions: {
        android: {
          extension: '.wav',
          outputFormat: 0, // AUDIO_OUTPUT_FORMAT_DEFAULT
          audioEncoder: 0, // AUDIO_ENCODER_DEFAULT
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          extension: '.wav',
          audioQuality: 0x7F, // AVAudioQuality.max
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
      },
      analysisInterval: 100,
      bufferSize: 4096,
      pitchTolerance: 50,
      minConfidence: 0.5,
      ...config
    }

    this.pitchDetector = new PitchDetector({
      sampleRate: this.config.recordingOptions.ios.sampleRate,
      bufferSize: this.config.bufferSize,
      minFreq: 80,
      maxFreq: 1000,
      threshold: 0.1
    })
  }

  /**
   * ìŒì • ë¶„ì„ ì‹œì‘
   */
  async startAnalysis(
    lyrics: LyricItem[],
    onAnalysis: (result: PitchAnalysisResult) => void
  ): Promise<void> {
    if (this.isAnalyzing) {
      await this.stopAnalysis()
    }

    try {
      // ì˜¤ë””ì˜¤ ê¶Œí•œ ìš”ì²­
      const { status } = await Audio.requestPermissionsAsync()
      if (status !== 'granted') {
        throw new Error('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤')
      }

      // ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì •
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        staysActiveInBackground: false,
        shouldDuckAndroid: false,
      })

      console.log('ğŸ¤ ìŒì • ë¶„ì„ ì‹œì‘')
      
      this.currentLyrics = lyrics
      this.analysisCallback = onAnalysis
      this.isAnalyzing = true
      this.analysisStartTime = Date.now()

      // ì‹¤ì œ ë…¹ìŒì€ ë‚˜ì¤‘ì— êµ¬í˜„í•˜ê³ , í˜„ì¬ëŠ” mock ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
      try {
        const recordingOptions = {
          ...this.config.recordingOptions,
          web: {
            mimeType: 'audio/wav',
            bitsPerSecond: 128000,
          }
        }
        
        const { recording } = await Audio.Recording.createAsync(
          recordingOptions,
          undefined, // status update callbackì€ undefinedë¡œ
          1000 // 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        )
        
        this.recording = recording
        console.log('âœ… ë…¹ìŒ ì‹œì‘ ì„±ê³µ')
      } catch (recordingError) {
        console.log('âš ï¸ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨, mock ëª¨ë“œë¡œ ì§„í–‰:', recordingError)
        // ë…¹ìŒ ì‹¤íŒ¨í•´ë„ mock ë°ì´í„°ë¡œ ê³„ì† ì§„í–‰
        this.recording = null
      }
      
      // ì£¼ê¸°ì  ë¶„ì„ ì‹œì‘
      this.startPeriodicAnalysis()

    } catch (error) {
      console.error('âŒ ìŒì • ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:', error)
      this.isAnalyzing = false
      throw error
    }
  }

  /**
   * ìŒì • ë¶„ì„ ì¤‘ë‹¨
   */
  async stopAnalysis(): Promise<void> {
    console.log('ğŸ›‘ ìŒì • ë¶„ì„ ì¤‘ë‹¨')
    
    this.isAnalyzing = false
    
    if (this.analysisTimer) {
      clearInterval(this.analysisTimer)
      this.analysisTimer = null
    }

    if (this.recording) {
      try {
        await this.recording.stopAndUnloadAsync()
      } catch (error) {
        console.error('ë…¹ìŒ ì¤‘ë‹¨ ì˜¤ë¥˜:', error)
      }
      this.recording = null
    }

    this.analysisCallback = null
  }

  /**
   * ì£¼ê¸°ì  ë¶„ì„ ë£¨í”„ ì‹œì‘
   */
  private startPeriodicAnalysis(): void {
    this.analysisTimer = setInterval(async () => {
      if (!this.isAnalyzing || !this.recording) return

      try {
        await this.performAnalysis()
      } catch (error) {
        console.error('ë¶„ì„ ì˜¤ë¥˜:', error)
      }
    }, this.config.analysisInterval)
  }

  /**
   * ì‹¤ì œ ìŒì • ë¶„ì„ ìˆ˜í–‰
   */
  private async performAnalysis(): Promise<void> {
    if (!this.analysisCallback) return

    try {
      // í˜„ì¬ ì‹œê°„ ê¸°ì¤€ ì˜ˆìƒ ìŒì • ì°¾ê¸° (startTime ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
      const analysisStartTime = Date.now()
      
      // ë¶„ì„ ì‹œì‘ ì‹œê°„ìœ¼ë¡œë¶€í„° ê²½ê³¼ëœ ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ê³„ì‚°
      const elapsedSeconds = (analysisStartTime - (this.analysisStartTime || analysisStartTime)) / 1000
      const currentLyric = this.findCurrentLyricByTime(elapsedSeconds)
      
      // ì„ì‹œ: ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„° ëŒ€ì‹  ëœë¤ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
      const mockAudioBuffer = this.generateMockAudioBuffer(currentLyric)
      
      // í”¼ì¹˜ ê²€ì¶œ
      const pitchResult = this.pitchDetector.detectPitch(mockAudioBuffer)
      
      // ëª©í‘œ ìŒì •ê³¼ ë¹„êµ ë¶„ì„
      const analysisResult = this.compareWithTarget(pitchResult, currentLyric, analysisStartTime)
      
      // ì½œë°± í˜¸ì¶œ
      this.analysisCallback(analysisResult)

    } catch (error) {
      console.error('ìŒì • ë¶„ì„ ìˆ˜í–‰ ì˜¤ë¥˜:', error)
    }
  }

  /**
   * í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ê°€ì‚¬/ìŒì • ì°¾ê¸° (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
   */
  private findCurrentLyric(currentTime: number): LyricItem | null {
    const timeInSeconds = currentTime / 1000
    
    return this.currentLyrics.find(lyric => 
      timeInSeconds >= lyric.startTime && timeInSeconds <= lyric.endTime
    ) || null
  }

  /**
   * ê²½ê³¼ ì‹œê°„ìœ¼ë¡œ í˜„ì¬ ê°€ì‚¬/ìŒì • ì°¾ê¸°
   */
  private findCurrentLyricByTime(elapsedSeconds: number): LyricItem | null {
    return this.currentLyrics.find(lyric => 
      elapsedSeconds >= lyric.startTime && elapsedSeconds <= lyric.endTime
    ) || null
  }

  /**
   * ê²€ì¶œëœ ìŒì •ê³¼ ëª©í‘œ ìŒì • ë¹„êµ
   */
  private compareWithTarget(
    pitchResult: PitchDetectionResult,
    currentLyric: LyricItem | null,
    timestamp: number
  ): PitchAnalysisResult {
    let targetPitch: { frequency: number; note: string; octave: number } | null = null
    let accuracy = 0
    let centsDifference = 0
    let isOnPitch = false

    if (currentLyric?.pitch && pitchResult.frequency > 0) {
      // MusicXML ìŒì •ì„ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜
      const targetFrequency = PitchUtils.musicXMLToFrequency(
        currentLyric.pitch.step,
        currentLyric.pitch.octave,
        currentLyric.pitch.alter || 0
      )

      targetPitch = {
        frequency: targetFrequency,
        note: currentLyric.pitch.step,
        octave: currentLyric.pitch.octave
      }

      // ì •í™•ë„ ê³„ì‚°
      centsDifference = PitchUtils.calculateCentsDifference(
        targetFrequency,
        pitchResult.frequency
      )
      
      accuracy = PitchUtils.calculatePitchAccuracy(
        targetFrequency,
        pitchResult.frequency,
        this.config.pitchTolerance
      )

      console.log('ğŸ¯ ìŒì • ë¹„êµ ê²°ê³¼:', {
        targetFreq: targetFrequency.toFixed(2) + 'Hz',
        detectedFreq: pitchResult.frequency.toFixed(2) + 'Hz',
        centsDifference: centsDifference.toFixed(1) + 'Â¢',
        accuracy: (accuracy * 100).toFixed(1) + '%',
        isOnPitch: Math.abs(centsDifference) <= this.config.pitchTolerance
      })

      isOnPitch = Math.abs(centsDifference) <= this.config.pitchTolerance && 
                  pitchResult.confidence >= this.config.minConfidence
    }

    return {
      currentPitch: pitchResult,
      targetPitch,
      accuracy,
      centsDifference,
      isOnPitch,
      lyricText: currentLyric?.text || '',
      timestamp
    }
  }

  /**
   * ì„ì‹œ Mock ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
   * ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
   */
  private generateMockAudioBuffer(currentLyric?: LyricItem | null): Float32Array {
    const buffer = new Float32Array(this.config.bufferSize)
    
    // ëª©í‘œ ìŒì •ì´ ìˆìœ¼ë©´ ê·¸ ì£¼íŒŒìˆ˜ ê·¼ì²˜ë¡œ, ì—†ìœ¼ë©´ ëœë¤
    let targetFrequency = 440 // ê¸°ë³¸ A4
    
    if (currentLyric?.pitch) {
      targetFrequency = PitchUtils.musicXMLToFrequency(
        currentLyric.pitch.step,
        currentLyric.pitch.octave,
        currentLyric.pitch.alter || 0
      )
      
      console.log('ğŸ¯ Mock ìƒì„± - ëª©í‘œ:', {
        step: currentLyric.pitch.step,
        octave: currentLyric.pitch.octave,
        alter: currentLyric.pitch.alter,
        targetFreq: targetFrequency
      })
    }
    
    // ë” ì •í™•í•œ Mock ìƒì„±: 90% í™•ë¥ ë¡œ ì •í™•í•œ ìŒì •, 10% í™•ë¥ ë¡œ ì•½ê°„ì˜ ì˜¤ì°¨
    let actualFrequency: number
    const accuracy = Math.random()
    
    if (accuracy > 0.1) {
      // 90% í™•ë¥ : ê±°ì˜ ì •í™•í•œ ìŒì • (Â±10ì„¼íŠ¸ ì´ë‚´)
      const centDeviation = (Math.random() - 0.5) * 20 // Â±10ì„¼íŠ¸
      actualFrequency = targetFrequency * Math.pow(2, centDeviation / 1200)
    } else {
      // 10% í™•ë¥ : ì•½ê°„ì˜ ì˜¤ì°¨ (Â±50ì„¼íŠ¸ ì´ë‚´)  
      const centDeviation = (Math.random() - 0.5) * 100 // Â±50ì„¼íŠ¸
      actualFrequency = targetFrequency * Math.pow(2, centDeviation / 1200)
    }
    
    console.log('ğŸµ Mock ìƒì„± ê²°ê³¼:', {
      targetFrequency: targetFrequency.toFixed(2),
      actualFrequency: actualFrequency.toFixed(2),
      difference: (actualFrequency - targetFrequency).toFixed(2) + 'Hz',
      centsDiff: (1200 * Math.log2(actualFrequency / targetFrequency)).toFixed(1) + 'Â¢'
    })
    
    const sampleRate = this.config.recordingOptions.ios.sampleRate
    
    // ì‚¬ì¸íŒŒ ìƒì„± (ì‹¤ì œ ì‚¬ëŒ ëª©ì†Œë¦¬ì²˜ëŸ¼ ì•½ê°„ì˜ ë³€ë™ ì¶”ê°€)
    for (let i = 0; i < buffer.length; i++) {
      const time = i / sampleRate
      const amplitude = 0.3 * (0.8 + 0.2 * Math.sin(2 * Math.PI * 5 * time)) // 5Hz ì§„í­ ë³€ì¡°
      buffer[i] = amplitude * Math.sin(2 * Math.PI * actualFrequency * time) * 
                  (0.9 + 0.1 * Math.random()) // ì•½ê°„ì˜ ë…¸ì´ì¦ˆ
    }
    
    return buffer
  }

  /**
   * ë¶„ì„ ìƒíƒœ í™•ì¸
   */
  get isRunning(): boolean {
    return this.isAnalyzing
  }

  /**
   * ì„¤ì • ì—…ë°ì´íŠ¸
   */
  updateConfig(newConfig: Partial<PitchAnalysisConfig>): void {
    this.config = { ...this.config, ...newConfig }
    
    // PitchDetector ì„¤ì •ë„ ì—…ë°ì´íŠ¸
    this.pitchDetector.updateConfig({
      sampleRate: this.config.recordingOptions.ios.sampleRate,
      bufferSize: this.config.bufferSize
    })
  }
}

/**
 * ìŒì • ë¶„ì„ ê²°ê³¼ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
 */
export class PitchAnalysisUtils {
  /**
   * ì •í™•ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜
   */
  static getAccuracyColor(accuracy: number): string {
    if (accuracy >= 0.8) return '#4CAF50'      // ì´ˆë¡ (ë§¤ìš° ì¢‹ìŒ)
    if (accuracy >= 0.6) return '#8BC34A'      // ì—°ì´ˆë¡ (ì¢‹ìŒ)
    if (accuracy >= 0.4) return '#FFEB3B'      // ë…¸ë‘ (ë³´í†µ)
    if (accuracy >= 0.2) return '#FF9800'      // ì£¼í™© (ë‚˜ì¨)
    return '#F44336'                           // ë¹¨ê°• (ë§¤ìš° ë‚˜ì¨)
  }

  /**
   * ì„¼íŠ¸ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·
   */
  static formatCentsDifference(cents: number): string {
    const absCents = Math.abs(cents)
    const sign = cents > 0 ? '+' : '-'
    return `${sign}${Math.round(absCents)}Â¢`
  }

  /**
   * ì •í™•ë„ë¥¼ í¼ì„¼íŠ¸ë¡œ í¬ë§·
   */
  static formatAccuracy(accuracy: number): string {
    return `${Math.round(accuracy * 100)}%`
  }

  /**
   * ì£¼íŒŒìˆ˜ë¥¼ ìŒì • ì´ë¦„ìœ¼ë¡œ í¬ë§· (ì˜ì–´)
   */
  static formatNoteName(frequency: number): string {
    if (frequency <= 0) return '-'
    const { note, octave, cents } = PitchUtils.frequencyToNoteName(frequency)
    const centsSuffix = Math.abs(cents) > 5 ? ` ${cents > 0 ? '+' : ''}${cents}Â¢` : ''
    return `${note}${octave}${centsSuffix}`
  }

  /**
   * ì£¼íŒŒìˆ˜ë¥¼ í•œê¸€ ìŒì • ì´ë¦„ìœ¼ë¡œ í¬ë§·
   */
  static formatKoreanNoteName(frequency: number): string {
    if (frequency <= 0) return '-'
    const { note, octave, cents } = PitchUtils.frequencyToKoreanNoteName(frequency)
    const centsSuffix = Math.abs(cents) > 5 ? ` ${cents > 0 ? '+' : ''}${cents}Â¢` : ''
    return `${note}${octave}${centsSuffix}`
  }

  /**
   * ìŒì • í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±
   * centsDifference: ì–‘ìˆ˜ = ê²€ì¶œìŒì´ ë†’ìŒ, ìŒìˆ˜ = ê²€ì¶œìŒì´ ë‚®ìŒ
   */
  static getPitchFeedback(centsDifference: number, accuracy: number): {
    message: string
    emoji: string
    color: string
  } {
    const color = this.getAccuracyColor(accuracy)
    
    console.log('ğŸ­ í”¼ë“œë°± ìƒì„±:', {
      centsDifference: centsDifference.toFixed(1) + 'Â¢',
      accuracy: (accuracy * 100).toFixed(1) + '%',
      interpretation: centsDifference > 0 ? 'ê²€ì¶œìŒì´ ë†’ìŒ' : centsDifference < 0 ? 'ê²€ì¶œìŒì´ ë‚®ìŒ' : 'ì •í™•'
    })
    
    // ë§¤ìš° ì •í™•í•¨ (Â±10ì„¼íŠ¸ ì´ë‚´)
    if (Math.abs(centsDifference) <= 10) {
      return {
        message: 'ì™„ë²½í•´ìš”! ğŸ‘',
        emoji: 'ğŸ¯',
        color
      }
    }
    
    // ì¢‹ìŒ (Â±25ì„¼íŠ¸ ì´ë‚´)
    if (Math.abs(centsDifference) <= 25) {
      return {
        message: 'ì¢‹ì•„ìš”! ê±°ì˜ ë§ì•„ìš” âœ¨',
        emoji: 'ğŸ‘',
        color
      }
    }
    
    // ì¡°ê¸ˆ ë†’ìŒ (25-50ì„¼íŠ¸ ë†’ìŒ) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë†’ìŒ
    if (centsDifference > 25 && centsDifference <= 50) {
      return {
        message: 'ì¡°ê¸ˆ ë‚®ì¶°ì£¼ì„¸ìš” ğŸ”½',
        emoji: 'â¬‡ï¸',
        color
      }
    }
    
    // ë§ì´ ë†’ìŒ (50ì„¼íŠ¸ ì´ìƒ ë†’ìŒ) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë†’ìŒ
    if (centsDifference > 50) {
      return {
        message: 'ë” ë‚®ì¶°ì£¼ì„¸ìš”! ğŸ”½ğŸ”½',
        emoji: 'â¬',
        color
      }
    }
    
    // ì¡°ê¸ˆ ë‚®ìŒ (-25 ~ -50ì„¼íŠ¸) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë‚®ìŒ
    if (centsDifference < -25 && centsDifference >= -50) {
      return {
        message: 'ì¡°ê¸ˆ ë†’ì—¬ì£¼ì„¸ìš” ğŸ”¼',
        emoji: 'â¬†ï¸',
        color
      }
    }
    
    // ë§ì´ ë‚®ìŒ (-50ì„¼íŠ¸ ì´í•˜) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë‚®ìŒ
    if (centsDifference < -50) {
      return {
        message: 'ë” ë†’ì—¬ì£¼ì„¸ìš”! ğŸ”¼ğŸ”¼',
        emoji: 'â«',
        color
      }
    }
    
    // ê¸°ë³¸ê°’
    return {
      message: 'ìŒì •ì„ ë§ì¶°ì£¼ì„¸ìš”',
      emoji: 'ğŸµ',
      color
    }
  }

  /**
   * ì •í™•ë„ì— ë”°ë¥¸ ê²©ë ¤ ë©”ì‹œì§€
   */
  static getEncouragementMessage(accuracy: number): string {
    if (accuracy >= 0.9) return 'ìµœê³ ì˜ˆìš”! ğŸŒŸ'
    if (accuracy >= 0.8) return 'í›Œë¥­í•´ìš”! â­'
    if (accuracy >= 0.7) return 'ì˜í•˜ê³  ìˆì–´ìš”! ğŸ‘'
    if (accuracy >= 0.6) return 'ì ì  ì¢‹ì•„ì§€ê³  ìˆì–´ìš”! ğŸ“ˆ'
    if (accuracy >= 0.4) return 'ì—°ìŠµí•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”! ğŸ’ª'
    return 'ì²œì²œíˆ ë§ì¶°ë³´ì„¸ìš”! ğŸµ'
  }

  /**
   * MusicXML ìŒì •ì„ í•œê¸€ë¡œ í¬ë§·
   */
  static formatMusicXMLKorean(step: string, octave: number, alter: number = 0): string {
    return PitchUtils.musicXMLToKoreanNoteName(step, octave, alter)
  }
}