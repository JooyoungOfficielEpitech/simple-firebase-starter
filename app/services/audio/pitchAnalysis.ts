/**
 * ìŒì • ë¶„ì„ ì„œë¹„ìŠ¤
 * ì‹¤ì‹œê°„ í”¼ì¹˜ ê²€ì¶œê³¼ MusicXML ìŒì • ë°ì´í„° ë¹„êµ ë¶„ì„
 */

import { Audio } from "expo-av"
import { PitchDetector, PitchDetectionResult, PitchUtils } from "./pitchDetection"
import type { LyricItem } from "@/services/musicxml/musicXMLParser"

export enum RecordingState {
  IDLE = 'idle',
  PREPARING = 'preparing', 
  READY = 'ready',
  RECORDING = 'recording',
  ERROR = 'error',
  MOCK_MODE = 'mock_mode'
}

export interface PitchAnalysisResult {
  currentPitch: PitchDetectionResult
  targetPitch: {
    frequency: number
    note: string
    octave: number
  } | null
  accuracy: number           // 0-1 ì •í™•ë„ ì ìˆ˜
  centsDifference: number    // ì„¼íŠ¸ ë‹¨ìœ„ ì°¨ì´ (-100 ~ +100)
  isOnPitch: boolean         // ì •í™•í•œ ìŒì •ì¸ì§€
  lyricText: string         // í˜„ì¬ ê°€ì‚¬
  timestamp: number         // ë¶„ì„ ì‹œì 
}

export interface PitchAnalysisConfig {
  recordingOptions: {
    android: {
      extension: ".wav"
      outputFormat: number
      audioEncoder: number
      sampleRate: number
      numberOfChannels: number
      bitRate: number
    }
    ios: {
      extension: ".wav"
      audioQuality: number
      sampleRate: number
      numberOfChannels: number
      bitRate: number
      linearPCMBitDepth: number
      linearPCMIsBigEndian: boolean
      linearPCMIsFloat: boolean
    }
  }
  analysisInterval: number    // ë¶„ì„ ê°„ê²© (ms)
  bufferSize: number         // ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸°
  pitchTolerance: number     // ìŒì • í—ˆìš© ì˜¤ì°¨ (cents)
  minConfidence: number      // ìµœì†Œ ì‹ ë¢°ë„
}

export class PitchAnalysisService {
  private pitchDetector: PitchDetector
  private recording: Audio.Recording | null = null
  private analysisTimer: NodeJS.Timeout | null = null
  private config: PitchAnalysisConfig
  private isAnalyzing = false
  private recordingState: RecordingState = RecordingState.IDLE
  private currentLyrics: LyricItem[] = []
  private analysisCallback: ((result: PitchAnalysisResult) => void) | null = null
  private analysisStartTime: number = 0

  constructor(config: Partial<PitchAnalysisConfig> = {}) {
    this.config = {
      recordingOptions: {
        android: {
          extension: '.wav',
          outputFormat: 0, // AUDIO_OUTPUT_FORMAT_DEFAULT
          audioEncoder: 0, // AUDIO_ENCODER_DEFAULT
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          extension: '.wav',
          audioQuality: 0x7F, // AVAudioQuality.max
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
      },
      analysisInterval: 100,
      bufferSize: 4096,
      pitchTolerance: 50,
      minConfidence: 0.5,
      ...config
    }

    this.pitchDetector = new PitchDetector({
      sampleRate: this.config.recordingOptions.ios.sampleRate,
      bufferSize: this.config.bufferSize,
      minFreq: 80,
      maxFreq: 1000,
      threshold: 0.1
    })
  }

  /**
   * ìŒì • ë¶„ì„ ì‹œì‘
   */
  async startAnalysis(
    lyrics: LyricItem[],
    onAnalysis: (result: PitchAnalysisResult) => void
  ): Promise<void> {
    if (this.isAnalyzing) {
      await this.stopAnalysis()
    }

    try {
      // ì˜¤ë””ì˜¤ ê¶Œí•œ ìš”ì²­
      const { status } = await Audio.requestPermissionsAsync()
      if (status !== 'granted') {
        throw new Error('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤')
      }

      // ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì •
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        staysActiveInBackground: false,
        shouldDuckAndroid: false,
      })

      console.log('ğŸ¤ ìŒì • ë¶„ì„ ì‹œì‘')
      
      this.currentLyrics = lyrics
      this.analysisCallback = onAnalysis
      this.isAnalyzing = true
      this.analysisStartTime = Date.now()

      // ë…¹ìŒ ìƒíƒœë¥¼ PREPARINGìœ¼ë¡œ ì„¤ì •
      this.recordingState = RecordingState.PREPARING

      // ì‹¤ì œ ë…¹ìŒ ì‹œë„
      try {
        const recordingOptions = {
          ...this.config.recordingOptions,
          web: {
            mimeType: 'audio/wav',
            bitsPerSecond: 128000,
          }
        }
        
        console.log('ğŸ”„ ë…¹ìŒ ì¤€ë¹„ ì¤‘...')
        const { recording } = await Audio.Recording.createAsync(
          recordingOptions,
          undefined, // status update callbackì€ undefinedë¡œ
          1000 // 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        )
        
        this.recording = recording
        this.recordingState = RecordingState.RECORDING
        console.log('âœ… ë…¹ìŒ ì‹œì‘ ì„±ê³µ - ì‹¤ì œ ë…¹ìŒ ëª¨ë“œ')
      } catch (recordingError) {
        console.log('âš ï¸ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨, mock ëª¨ë“œë¡œ ì§„í–‰:', recordingError)
        // ë…¹ìŒ ì‹¤íŒ¨ì‹œ mock ëª¨ë“œë¡œ ì „í™˜
        this.recording = null
        this.recordingState = RecordingState.MOCK_MODE
        console.log('ğŸ­ Mock ëª¨ë“œë¡œ ë¶„ì„ ì§„í–‰')
      }
      
      // ì£¼ê¸°ì  ë¶„ì„ ì‹œì‘
      this.startPeriodicAnalysis()

    } catch (error) {
      console.error('âŒ ìŒì • ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:', error)
      this.isAnalyzing = false
      this.recordingState = RecordingState.ERROR
      
      // ì—ëŸ¬ ì •ë³´ ìƒì„¸ ë¡œê¹…
      if (error instanceof Error) {
        console.error('âŒ ì—ëŸ¬ ìƒì„¸:', {
          name: error.name,
          message: error.message,
          stack: error.stack
        })
      }
      
      throw error
    }
  }

  /**
   * ìŒì • ë¶„ì„ ì¤‘ë‹¨
   */
  async stopAnalysis(): Promise<void> {
    console.log('ğŸ›‘ ìŒì • ë¶„ì„ ì¤‘ë‹¨')
    
    this.isAnalyzing = false
    
    // ë¶„ì„ íƒ€ì´ë¨¸ ì •ë¦¬
    if (this.analysisTimer) {
      clearInterval(this.analysisTimer)
      this.analysisTimer = null
    }

    // ì•ˆì „í•œ ë…¹ìŒ ì •ë¦¬
    await this.safeStopRecording()

    // ì½œë°± ì •ë¦¬
    this.analysisCallback = null
    
    // ìƒíƒœ ì´ˆê¸°í™”
    this.recordingState = RecordingState.IDLE
    console.log('âœ… ìŒì • ë¶„ì„ ì™„ì „íˆ ì¤‘ë‹¨ë¨')
  }

  /**
   * ì•ˆì „í•œ ë…¹ìŒ ì¤‘ë‹¨ ë©”ì„œë“œ
   */
  private async safeStopRecording(): Promise<void> {
    console.log(`ğŸ” ë…¹ìŒ ìƒíƒœ í™•ì¸: ${this.recordingState}`)
    
    // Mock ëª¨ë“œì´ê±°ë‚˜ ë…¹ìŒì´ ì—†ëŠ” ê²½ìš° ë°”ë¡œ ë¦¬í„´
    if (this.recordingState === RecordingState.MOCK_MODE || !this.recording) {
      console.log('ğŸ“ Mock ëª¨ë“œ ë˜ëŠ” ë…¹ìŒ ì—†ìŒ - ì•ˆì „í•˜ê²Œ íŒ¨ìŠ¤')
      this.recording = null
      return
    }

    // ë…¹ìŒì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ì¤‘ë‹¨ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸
    if (this.recording && this.recordingState === RecordingState.RECORDING) {
      try {
        console.log('â¹ï¸ ì‹¤ì œ ë…¹ìŒ ì¤‘ë‹¨ ì‹œë„...')
        
        // ë…¹ìŒ ìƒíƒœ í™•ì¸
        const status = await this.recording.getStatusAsync()
        console.log('ğŸ“Š ë…¹ìŒ ìƒíƒœ:', {
          canRecord: status.canRecord,
          isRecording: status.isRecording,
          isDoneRecording: status.isDoneRecording
        })
        
        // ì‹¤ì œë¡œ ë…¹ìŒ ì¤‘ì¸ ê²½ìš°ì—ë§Œ ì¤‘ë‹¨
        if (status.canRecord || status.isRecording) {
          await this.recording.stopAndUnloadAsync()
          console.log('âœ… ë…¹ìŒ ì •ìƒ ì¤‘ë‹¨ë¨')
        } else {
          console.log('âš ï¸ ë…¹ìŒì´ ì´ë¯¸ ì¤‘ë‹¨ëœ ìƒíƒœ')
        }
      } catch (error) {
        console.error('âŒ ë…¹ìŒ ì¤‘ë‹¨ ì¤‘ ì˜¤ë¥˜ (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë¨):', error)
        // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰ - ì´ë¯¸ ì¤‘ë‹¨ëœ ë…¹ìŒì¼ ê°€ëŠ¥ì„±
      }
    } else {
      console.log('âš ï¸ ë…¹ìŒ ìƒíƒœê°€ ì¤‘ë‹¨ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ')
    }

    // ë…¹ìŒ ê°ì²´ ì •ë¦¬
    this.recording = null
    console.log('ğŸ§¹ ë…¹ìŒ ê°ì²´ ì •ë¦¬ ì™„ë£Œ')
  }

  /**
   * ì£¼ê¸°ì  ë¶„ì„ ë£¨í”„ ì‹œì‘
   */
  private startPeriodicAnalysis(): void {
    this.analysisTimer = setInterval(async () => {
      // ë¶„ì„ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ìƒíƒœë©´ ì¤‘ë‹¨
      if (!this.isAnalyzing || 
          (this.recordingState !== RecordingState.RECORDING && this.recordingState !== RecordingState.MOCK_MODE)) {
        return
      }

      try {
        await this.performAnalysis()
      } catch (error) {
        console.error('ğŸš¨ ë¶„ì„ ì˜¤ë¥˜ (ë³µêµ¬ ê°€ëŠ¥):', error)
        
        // ë…¹ìŒ ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° Mock ëª¨ë“œë¡œ ì „í™˜
        if (error instanceof Error && error.message.includes('Recorder') && this.recordingState === RecordingState.RECORDING) {
          console.log('ğŸ­ ë…¹ìŒ ì—ëŸ¬ ê°ì§€ - Mock ëª¨ë“œë¡œ ìë™ ì „í™˜')
          this.recordingState = RecordingState.MOCK_MODE
          this.recording = null
        }
        
        // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰ (ë³µêµ¬ ë¡œì§)
      }
    }, this.config.analysisInterval)
  }

  /**
   * ì‹¤ì œ ìŒì • ë¶„ì„ ìˆ˜í–‰
   */
  private async performAnalysis(): Promise<void> {
    if (!this.analysisCallback) return

    try {
      // í˜„ì¬ ì‹œê°„ ê¸°ì¤€ ì˜ˆìƒ ìŒì • ì°¾ê¸° (startTime ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
      const analysisStartTime = Date.now()
      
      // ë¶„ì„ ì‹œì‘ ì‹œê°„ìœ¼ë¡œë¶€í„° ê²½ê³¼ëœ ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ê³„ì‚°
      const elapsedSeconds = (analysisStartTime - (this.analysisStartTime || analysisStartTime)) / 1000
      const currentLyric = this.findCurrentLyricByTime(elapsedSeconds)
      
      // ì„ì‹œ: ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„° ëŒ€ì‹  ëœë¤ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
      const mockAudioBuffer = this.generateMockAudioBuffer(currentLyric)
      
      // í”¼ì¹˜ ê²€ì¶œ
      const pitchResult = this.pitchDetector.detectPitch(mockAudioBuffer)
      
      // ëª©í‘œ ìŒì •ê³¼ ë¹„êµ ë¶„ì„
      const analysisResult = this.compareWithTarget(pitchResult, currentLyric, analysisStartTime)
      
      // ì½œë°± í˜¸ì¶œ
      this.analysisCallback(analysisResult)

    } catch (error) {
      console.error('ìŒì • ë¶„ì„ ìˆ˜í–‰ ì˜¤ë¥˜:', error)
    }
  }

  /**
   * í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ê°€ì‚¬/ìŒì • ì°¾ê¸° (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
   */
  private findCurrentLyric(currentTime: number): LyricItem | null {
    const timeInSeconds = currentTime / 1000
    
    return this.currentLyrics.find(lyric => 
      timeInSeconds >= lyric.startTime && timeInSeconds <= lyric.endTime
    ) || null
  }

  /**
   * ê²½ê³¼ ì‹œê°„ìœ¼ë¡œ í˜„ì¬ ê°€ì‚¬/ìŒì • ì°¾ê¸°
   */
  private findCurrentLyricByTime(elapsedSeconds: number): LyricItem | null {
    return this.currentLyrics.find(lyric => 
      elapsedSeconds >= lyric.startTime && elapsedSeconds <= lyric.endTime
    ) || null
  }

  /**
   * ê²€ì¶œëœ ìŒì •ê³¼ ëª©í‘œ ìŒì • ë¹„êµ
   */
  private compareWithTarget(
    pitchResult: PitchDetectionResult,
    currentLyric: LyricItem | null,
    timestamp: number
  ): PitchAnalysisResult {
    let targetPitch: { frequency: number; note: string; octave: number } | null = null
    let accuracy = 0
    let centsDifference = 0
    let isOnPitch = false

    if (currentLyric?.pitch && pitchResult.frequency > 0) {
      // MusicXML ìŒì •ì„ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜
      const targetFrequency = PitchUtils.musicXMLToFrequency(
        currentLyric.pitch.step,
        currentLyric.pitch.octave,
        currentLyric.pitch.alter || 0
      )

      targetPitch = {
        frequency: targetFrequency,
        note: currentLyric.pitch.step,
        octave: currentLyric.pitch.octave
      }

      // ì •í™•ë„ ê³„ì‚°
      centsDifference = PitchUtils.calculateCentsDifference(
        targetFrequency,
        pitchResult.frequency
      )
      
      accuracy = PitchUtils.calculatePitchAccuracy(
        targetFrequency,
        pitchResult.frequency,
        this.config.pitchTolerance
      )

      console.log('ğŸ¯ ìŒì • ë¹„êµ ê²°ê³¼:', {
        targetFreq: targetFrequency.toFixed(2) + 'Hz',
        detectedFreq: pitchResult.frequency.toFixed(2) + 'Hz',
        centsDifference: centsDifference.toFixed(1) + 'Â¢',
        accuracy: (accuracy * 100).toFixed(1) + '%',
        isOnPitch: Math.abs(centsDifference) <= this.config.pitchTolerance
      })

      isOnPitch = Math.abs(centsDifference) <= this.config.pitchTolerance && 
                  pitchResult.confidence >= this.config.minConfidence
    }

    return {
      currentPitch: pitchResult,
      targetPitch,
      accuracy,
      centsDifference,
      isOnPitch,
      lyricText: currentLyric?.text || '',
      timestamp
    }
  }

  /**
   * ì„ì‹œ Mock ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
   * ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
   */
  private generateMockAudioBuffer(currentLyric?: LyricItem | null): Float32Array {
    const buffer = new Float32Array(this.config.bufferSize)
    
    // ëª©í‘œ ìŒì •ì´ ìˆìœ¼ë©´ ê·¸ ì£¼íŒŒìˆ˜ ê·¼ì²˜ë¡œ, ì—†ìœ¼ë©´ ëœë¤
    let targetFrequency = 440 // ê¸°ë³¸ A4
    
    if (currentLyric?.pitch) {
      targetFrequency = PitchUtils.musicXMLToFrequency(
        currentLyric.pitch.step,
        currentLyric.pitch.octave,
        currentLyric.pitch.alter || 0
      )
      
      console.log('ğŸ¯ Mock ìƒì„± - ëª©í‘œ:', {
        step: currentLyric.pitch.step,
        octave: currentLyric.pitch.octave,
        alter: currentLyric.pitch.alter,
        targetFreq: targetFrequency
      })
    }
    
    // ë” ì •í™•í•œ Mock ìƒì„±: 90% í™•ë¥ ë¡œ ì •í™•í•œ ìŒì •, 10% í™•ë¥ ë¡œ ì•½ê°„ì˜ ì˜¤ì°¨
    let actualFrequency: number
    const accuracy = Math.random()
    
    if (accuracy > 0.1) {
      // 90% í™•ë¥ : ê±°ì˜ ì •í™•í•œ ìŒì • (Â±10ì„¼íŠ¸ ì´ë‚´)
      const centDeviation = (Math.random() - 0.5) * 20 // Â±10ì„¼íŠ¸
      actualFrequency = targetFrequency * Math.pow(2, centDeviation / 1200)
    } else {
      // 10% í™•ë¥ : ì•½ê°„ì˜ ì˜¤ì°¨ (Â±50ì„¼íŠ¸ ì´ë‚´)  
      const centDeviation = (Math.random() - 0.5) * 100 // Â±50ì„¼íŠ¸
      actualFrequency = targetFrequency * Math.pow(2, centDeviation / 1200)
    }
    
    console.log('ğŸµ Mock ìƒì„± ê²°ê³¼:', {
      targetFrequency: targetFrequency.toFixed(2),
      actualFrequency: actualFrequency.toFixed(2),
      difference: (actualFrequency - targetFrequency).toFixed(2) + 'Hz',
      centsDiff: (1200 * Math.log2(actualFrequency / targetFrequency)).toFixed(1) + 'Â¢'
    })
    
    const sampleRate = this.config.recordingOptions.ios.sampleRate
    
    // ì‚¬ì¸íŒŒ ìƒì„± (ì‹¤ì œ ì‚¬ëŒ ëª©ì†Œë¦¬ì²˜ëŸ¼ ì•½ê°„ì˜ ë³€ë™ ì¶”ê°€)
    for (let i = 0; i < buffer.length; i++) {
      const time = i / sampleRate
      const amplitude = 0.3 * (0.8 + 0.2 * Math.sin(2 * Math.PI * 5 * time)) // 5Hz ì§„í­ ë³€ì¡°
      buffer[i] = amplitude * Math.sin(2 * Math.PI * actualFrequency * time) * 
                  (0.9 + 0.1 * Math.random()) // ì•½ê°„ì˜ ë…¸ì´ì¦ˆ
    }
    
    return buffer
  }

  /**
   * ë¶„ì„ ìƒíƒœ í™•ì¸
   */
  get isRunning(): boolean {
    return this.isAnalyzing
  }

  /**
   * í˜„ì¬ ë…¹ìŒ ìƒíƒœ í™•ì¸
   */
  get currentRecordingState(): RecordingState {
    return this.recordingState
  }

  /**
   * Mock ëª¨ë“œ ì—¬ë¶€ í™•ì¸
   */
  get isInMockMode(): boolean {
    return this.recordingState === RecordingState.MOCK_MODE
  }

  /**
   * ì‹¤ì œ ë…¹ìŒ ëª¨ë“œ ì—¬ë¶€ í™•ì¸
   */
  get isRecording(): boolean {
    return this.recordingState === RecordingState.RECORDING
  }

  /**
   * ì„¤ì • ì—…ë°ì´íŠ¸
   */
  updateConfig(newConfig: Partial<PitchAnalysisConfig>): void {
    this.config = { ...this.config, ...newConfig }
    
    // PitchDetector ì„¤ì •ë„ ì—…ë°ì´íŠ¸
    this.pitchDetector.updateConfig({
      sampleRate: this.config.recordingOptions.ios.sampleRate,
      bufferSize: this.config.bufferSize
    })
  }
}

/**
 * ìŒì • ë¶„ì„ ê²°ê³¼ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
 */
export class PitchAnalysisUtils {
  /**
   * ì •í™•ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜
   */
  static getAccuracyColor(accuracy: number): string {
    if (accuracy >= 0.8) return '#4CAF50'      // ì´ˆë¡ (ë§¤ìš° ì¢‹ìŒ)
    if (accuracy >= 0.6) return '#8BC34A'      // ì—°ì´ˆë¡ (ì¢‹ìŒ)
    if (accuracy >= 0.4) return '#FFEB3B'      // ë…¸ë‘ (ë³´í†µ)
    if (accuracy >= 0.2) return '#FF9800'      // ì£¼í™© (ë‚˜ì¨)
    return '#F44336'                           // ë¹¨ê°• (ë§¤ìš° ë‚˜ì¨)
  }

  /**
   * ì„¼íŠ¸ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·
   */
  static formatCentsDifference(cents: number): string {
    const absCents = Math.abs(cents)
    const sign = cents > 0 ? '+' : '-'
    return `${sign}${Math.round(absCents)}Â¢`
  }

  /**
   * ì •í™•ë„ë¥¼ í¼ì„¼íŠ¸ë¡œ í¬ë§·
   */
  static formatAccuracy(accuracy: number): string {
    return `${Math.round(accuracy * 100)}%`
  }

  /**
   * ì£¼íŒŒìˆ˜ë¥¼ ìŒì • ì´ë¦„ìœ¼ë¡œ í¬ë§· (ì˜ì–´)
   */
  static formatNoteName(frequency: number): string {
    if (frequency <= 0) return '-'
    const { note, octave, cents } = PitchUtils.frequencyToNoteName(frequency)
    const centsSuffix = Math.abs(cents) > 5 ? ` ${cents > 0 ? '+' : ''}${cents}Â¢` : ''
    return `${note}${octave}${centsSuffix}`
  }

  /**
   * ì£¼íŒŒìˆ˜ë¥¼ í•œê¸€ ìŒì • ì´ë¦„ìœ¼ë¡œ í¬ë§·
   */
  static formatKoreanNoteName(frequency: number): string {
    if (frequency <= 0) return '-'
    const { note, octave, cents } = PitchUtils.frequencyToKoreanNoteName(frequency)
    const centsSuffix = Math.abs(cents) > 5 ? ` ${cents > 0 ? '+' : ''}${cents}Â¢` : ''
    return `${note}${octave}${centsSuffix}`
  }

  /**
   * ìŒì • í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±
   * centsDifference: ì–‘ìˆ˜ = ê²€ì¶œìŒì´ ë†’ìŒ, ìŒìˆ˜ = ê²€ì¶œìŒì´ ë‚®ìŒ
   */
  static getPitchFeedback(centsDifference: number, accuracy: number): {
    message: string
    emoji: string
    color: string
  } {
    const color = this.getAccuracyColor(accuracy)
    
    console.log('ğŸ­ í”¼ë“œë°± ìƒì„±:', {
      centsDifference: centsDifference.toFixed(1) + 'Â¢',
      accuracy: (accuracy * 100).toFixed(1) + '%',
      interpretation: centsDifference > 0 ? 'ê²€ì¶œìŒì´ ë†’ìŒ' : centsDifference < 0 ? 'ê²€ì¶œìŒì´ ë‚®ìŒ' : 'ì •í™•'
    })
    
    // ë§¤ìš° ì •í™•í•¨ (Â±10ì„¼íŠ¸ ì´ë‚´)
    if (Math.abs(centsDifference) <= 10) {
      return {
        message: 'ì™„ë²½í•´ìš”! ğŸ‘',
        emoji: 'ğŸ¯',
        color
      }
    }
    
    // ì¢‹ìŒ (Â±25ì„¼íŠ¸ ì´ë‚´)
    if (Math.abs(centsDifference) <= 25) {
      return {
        message: 'ì¢‹ì•„ìš”! ê±°ì˜ ë§ì•„ìš” âœ¨',
        emoji: 'ğŸ‘',
        color
      }
    }
    
    // ì¡°ê¸ˆ ë†’ìŒ (25-50ì„¼íŠ¸ ë†’ìŒ) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë†’ìŒ
    if (centsDifference > 25 && centsDifference <= 50) {
      return {
        message: 'ì¡°ê¸ˆ ë‚®ì¶°ì£¼ì„¸ìš” ğŸ”½',
        emoji: 'â¬‡ï¸',
        color
      }
    }
    
    // ë§ì´ ë†’ìŒ (50ì„¼íŠ¸ ì´ìƒ ë†’ìŒ) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë†’ìŒ
    if (centsDifference > 50) {
      return {
        message: 'ë” ë‚®ì¶°ì£¼ì„¸ìš”! ğŸ”½ğŸ”½',
        emoji: 'â¬',
        color
      }
    }
    
    // ì¡°ê¸ˆ ë‚®ìŒ (-25 ~ -50ì„¼íŠ¸) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë‚®ìŒ
    if (centsDifference < -25 && centsDifference >= -50) {
      return {
        message: 'ì¡°ê¸ˆ ë†’ì—¬ì£¼ì„¸ìš” ğŸ”¼',
        emoji: 'â¬†ï¸',
        color
      }
    }
    
    // ë§ì´ ë‚®ìŒ (-50ì„¼íŠ¸ ì´í•˜) - ê²€ì¶œëœ ìŒì´ ëª©í‘œë³´ë‹¤ ë‚®ìŒ
    if (centsDifference < -50) {
      return {
        message: 'ë” ë†’ì—¬ì£¼ì„¸ìš”! ğŸ”¼ğŸ”¼',
        emoji: 'â«',
        color
      }
    }
    
    // ê¸°ë³¸ê°’
    return {
      message: 'ìŒì •ì„ ë§ì¶°ì£¼ì„¸ìš”',
      emoji: 'ğŸµ',
      color
    }
  }

  /**
   * ì •í™•ë„ì— ë”°ë¥¸ ê²©ë ¤ ë©”ì‹œì§€
   */
  static getEncouragementMessage(accuracy: number): string {
    if (accuracy >= 0.9) return 'ìµœê³ ì˜ˆìš”! ğŸŒŸ'
    if (accuracy >= 0.8) return 'í›Œë¥­í•´ìš”! â­'
    if (accuracy >= 0.7) return 'ì˜í•˜ê³  ìˆì–´ìš”! ğŸ‘'
    if (accuracy >= 0.6) return 'ì ì  ì¢‹ì•„ì§€ê³  ìˆì–´ìš”! ğŸ“ˆ'
    if (accuracy >= 0.4) return 'ì—°ìŠµí•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”! ğŸ’ª'
    return 'ì²œì²œíˆ ë§ì¶°ë³´ì„¸ìš”! ğŸµ'
  }

  /**
   * MusicXML ìŒì •ì„ í•œê¸€ë¡œ í¬ë§·
   */
  static formatMusicXMLKorean(step: string, octave: number, alter: number = 0): string {
    return PitchUtils.musicXMLToKoreanNoteName(step, octave, alter)
  }
}